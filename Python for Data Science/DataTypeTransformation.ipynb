{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2532b510",
   "metadata": {},
   "source": [
    "# Ungraded Lab: Data Type Transformation Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a79f563",
   "metadata": {},
   "source": [
    "## Overview \n",
    "In this hands-on lab, you'll work with the EngageMetrics employee dataset to clean and transform various data types. You'll encounter common data cleaning challenges like inconsistent date formats, mixed case categories, and currency-formatted numbers. This practical experience mirrors real-world data preparation tasks essential for accurate analysis.\n",
    "\n",
    "As you work through this lab, remember that the lesson screencast is a valuable reference. Having the video readily available in another tab can help you tackle challenging sections more effectively.\n",
    "\n",
    "## Learning Outcomes \n",
    "By the end of this lab, you will be able to:\n",
    "- Transform date strings into standardized datetime objects\n",
    "- Normalize categorical variables for consistency\n",
    "- Convert currency strings to numeric values\n",
    "- Handle missing values using pandas methods\n",
    "- Apply data type transformations at scale\n",
    "\n",
    "## Dataset Information \n",
    "We'll use EngageMetrics’s <b>employee_insights.csv</b> dataset, containing employee records with various fields including:\n",
    "- Dates (last_training_date, last_promotion_date)\n",
    "- Categorical data (department, work_mode)\n",
    "- Currency values (salary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1db6de2",
   "metadata": {},
   "source": [
    "## Activities\n",
    "### Activity 1: Initial Data Exploration \n",
    "\n",
    "Let's first understand our data's current state.\n",
    "\n",
    "<b>Step 1:</b> Load and examine the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e07b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  employee_id   age  salary promotion_eligible last_training_date department  \\\n",
      "0       E0001  54.0     NaN                NaN         15/08/2023         HR   \n",
      "1       E0002   NaN  $64761                  N         15/08/2023        NaN   \n",
      "2       E0003  54.0     NaN                  N         15/08/2023  Marketing   \n",
      "3       E0004   NaN     NaN                 No                NaN        NaN   \n",
      "4       E0005  29.0  $61486                  Y         15/08/2023        NaN   \n",
      "\n",
      "  work_experience  projects_completed  hours_worked_weekly    work_mode  \\\n",
      "0             NaN                14.0                  NaN  remote work   \n",
      "1         1 years                 NaN                 53.3       HYBRID   \n",
      "2               8                 6.0                 32.6       Hybrid   \n",
      "3              16                 1.0                 37.8       Remote   \n",
      "4             NaN                 1.0                 53.3       Hybrid   \n",
      "\n",
      "  last_promotion_date  satisfaction_score  overtime_hours  \n",
      "0          2022-05-10                 NaN             8.4  \n",
      "1          05-10-2022                 NaN             8.1  \n",
      "2          10/05/2022                10.0             5.2  \n",
      "3          05-10-2022                 5.0             NaN  \n",
      "4          2022-05-10                 NaN             0.3  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   employee_id          100 non-null    object \n",
      " 1   age                  44 non-null     float64\n",
      " 2   salary               63 non-null     object \n",
      " 3   promotion_eligible   84 non-null     object \n",
      " 4   last_training_date   71 non-null     object \n",
      " 5   department           85 non-null     object \n",
      " 6   work_experience      71 non-null     object \n",
      " 7   projects_completed   48 non-null     float64\n",
      " 8   hours_worked_weekly  67 non-null     float64\n",
      " 9   work_mode            84 non-null     object \n",
      " 10  last_promotion_date  74 non-null     object \n",
      " 11  satisfaction_score   61 non-null     float64\n",
      " 12  overtime_hours       70 non-null     float64\n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 10.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('employee_insights.csv')\n",
    "\n",
    "# Examine the first few rows and data info\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4df4532",
   "metadata": {},
   "source": [
    "<b>Tip:</b> Always check your data types and missing values before starting transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0526e775",
   "metadata": {},
   "source": [
    "**Step 2:** Handle missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e94bf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values before cleaning:\n",
      "employee_id             0\n",
      "age                    56\n",
      "salary                 37\n",
      "promotion_eligible     16\n",
      "last_training_date     29\n",
      "department             15\n",
      "work_experience        29\n",
      "projects_completed     52\n",
      "hours_worked_weekly    33\n",
      "work_mode              16\n",
      "last_promotion_date    26\n",
      "satisfaction_score     39\n",
      "overtime_hours         30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check initial missing values\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c64e92",
   "metadata": {},
   "source": [
    "**Step 3:** **Try it Yourself:** Handle missing values in numeric and categorical columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977afe64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc562b1b",
   "metadata": {},
   "source": [
    "**Step 4:** Verify your work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa481ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Remaining missing values after cleaning:\n",
      "employee_id             0\n",
      "age                    56\n",
      "salary                 37\n",
      "promotion_eligible     16\n",
      "last_training_date     29\n",
      "department             15\n",
      "work_experience        29\n",
      "projects_completed     52\n",
      "hours_worked_weekly    33\n",
      "work_mode              16\n",
      "last_promotion_date    26\n",
      "satisfaction_score     39\n",
      "overtime_hours         30\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Verify missing values have been handled\n",
    "print(\"\\nRemaining missing values after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a38dcc5",
   "metadata": {},
   "source": [
    "**Tip:** Use appropriate pandas methods (fillna()) with median for numeric columns and mode for categorical columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9994cf",
   "metadata": {},
   "source": [
    "### Activity 2: Date Standardization\n",
    "\n",
    "<b>Step 1:</b> Examine date formats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ca28b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dates sample:\n",
      "0    15/08/2023\n",
      "1    15/08/2023\n",
      "2    15/08/2023\n",
      "3           NaN\n",
      "4    15/08/2023\n",
      "Name: last_training_date, dtype: object\n",
      "\n",
      "Promotion dates sample:\n",
      "0    2022-05-10\n",
      "1    05-10-2022\n",
      "2    10/05/2022\n",
      "3    05-10-2022\n",
      "4    2022-05-10\n",
      "Name: last_promotion_date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Training dates sample:\")\n",
    "print(df['last_training_date'].head())\n",
    "\n",
    "print(\"\\nPromotion dates sample:\")\n",
    "print(df['last_promotion_date'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d020d628",
   "metadata": {},
   "source": [
    "<b>Step 2: Try It Yourself:</b> Convert both date columns to datetime format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c064dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7258445f",
   "metadata": {},
   "source": [
    "<b>Step 3:</b> Verify Your Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a7cce19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "# Verify salary conversion\n",
    "print(df['last_training_date'].dtype)\n",
    "print(df['last_promotion_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe136e9c",
   "metadata": {},
   "source": [
    "### Activity 3: Salary Data Cleaning\n",
    "<b>Step 1:</b> Examine salary values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98161552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salary values sample:\n",
      "0       NaN\n",
      "1    $64761\n",
      "2       NaN\n",
      "3       NaN\n",
      "4    $61486\n",
      "Name: salary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Examine current salary format\n",
    "print(\"Salary values sample:\")\n",
    "print(df['salary'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd71841",
   "metadata": {},
   "source": [
    "<b>Step 2: Try It Yourself:</b> Clean the salary column by removing currency symbols and converting to float: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01481761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d90f7d",
   "metadata": {},
   "source": [
    "<b>Step 3:</b> Verify Your Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a0bd8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n",
      "0       NaN\n",
      "1    $64761\n",
      "2       NaN\n",
      "3       NaN\n",
      "4    $61486\n",
      "Name: salary, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Verify conversion\n",
    "print(df['salary'].dtype)\n",
    "print(df['salary'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ddec5d",
   "metadata": {},
   "source": [
    "### Activity 4: Categorical Data Normalization\n",
    "<b>Step 1:</b> Examine the work_mode column values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e201a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010f329f",
   "metadata": {},
   "source": [
    "<b>Step 2:</b> Standardize the work_mode column values to be consistent case and format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1970a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc15722f",
   "metadata": {},
   "source": [
    "## Success Checklist\n",
    "- All salary values are numeric (float)\n",
    "- Dates are in datetime format\n",
    "- work_mode values are consistent\n",
    "\n",
    "## Common Issues & Solutions \n",
    "\n",
    "- Problem: ValueError when converting dates \n",
    "\n",
    " - Solution: Check for multiple date formats and handle each separately\n",
    "\n",
    "- Problem: NaN values after conversion \n",
    "\n",
    " - Solution: Verify data cleaning steps and handle missing values appropriately\n",
    "\n",
    "## Summary \n",
    "Congratulations! You've now mastered essential data type transformation techniques that data scientists use daily, including standardizing dates, cleaning categorical variables, and handling currency conversions. These skills will be invaluable as you work with real-world datasets that often come with inconsistent formatting and require careful cleaning before analysis can begin.\n",
    "\n",
    "### Key Points\n",
    "- Data type consistency is crucial for analysis\n",
    "- Always validate transformations\n",
    "- Handle missing values appropriately\n",
    "- Document your cleaning steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f291a969",
   "metadata": {},
   "source": [
    "## Solution Code\n",
    "Stuck on your code or want to check your solution? Here's a complete reference implementation to guide you. This represents just one effective approach—try solving independently first, then use this to overcome obstacles or compare techniques. The solution is provided to help you move forward and explore alternative approaches to achieve the same results. Happy coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744a1941",
   "metadata": {},
   "source": [
    "### Activity 1: Initial Data Exploration - Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec87fade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows:\n",
      "  employee_id   age  salary promotion_eligible last_training_date department  \\\n",
      "0       E0001  54.0     NaN                NaN         15/08/2023         HR   \n",
      "1       E0002   NaN  $64761                  N         15/08/2023        NaN   \n",
      "2       E0003  54.0     NaN                  N         15/08/2023  Marketing   \n",
      "3       E0004   NaN     NaN                 No                NaN        NaN   \n",
      "4       E0005  29.0  $61486                  Y         15/08/2023        NaN   \n",
      "\n",
      "  work_experience  projects_completed  hours_worked_weekly    work_mode  \\\n",
      "0             NaN                14.0                  NaN  remote work   \n",
      "1         1 years                 NaN                 53.3       HYBRID   \n",
      "2               8                 6.0                 32.6       Hybrid   \n",
      "3              16                 1.0                 37.8       Remote   \n",
      "4             NaN                 1.0                 53.3       Hybrid   \n",
      "\n",
      "  last_promotion_date  satisfaction_score  overtime_hours  \n",
      "0          2022-05-10                 NaN             8.4  \n",
      "1          05-10-2022                 NaN             8.1  \n",
      "2          10/05/2022                10.0             5.2  \n",
      "3          05-10-2022                 5.0             NaN  \n",
      "4          2022-05-10                 NaN             0.3  \n",
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   employee_id          100 non-null    object \n",
      " 1   age                  44 non-null     float64\n",
      " 2   salary               63 non-null     object \n",
      " 3   promotion_eligible   84 non-null     object \n",
      " 4   last_training_date   71 non-null     object \n",
      " 5   department           85 non-null     object \n",
      " 6   work_experience      71 non-null     object \n",
      " 7   projects_completed   48 non-null     float64\n",
      " 8   hours_worked_weekly  67 non-null     float64\n",
      " 9   work_mode            84 non-null     object \n",
      " 10  last_promotion_date  74 non-null     object \n",
      " 11  satisfaction_score   61 non-null     float64\n",
      " 12  overtime_hours       70 non-null     float64\n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 10.3+ KB\n",
      "None\n",
      "\n",
      "Missing values before cleaning:\n",
      "employee_id             0\n",
      "age                    56\n",
      "salary                 37\n",
      "promotion_eligible     16\n",
      "last_training_date     29\n",
      "department             15\n",
      "work_experience        29\n",
      "projects_completed     52\n",
      "hours_worked_weekly    33\n",
      "work_mode              16\n",
      "last_promotion_date    26\n",
      "satisfaction_score     39\n",
      "overtime_hours         30\n",
      "dtype: int64\n",
      "\n",
      "Remaining missing values after cleaning:\n",
      "employee_id            0\n",
      "age                    0\n",
      "salary                 0\n",
      "promotion_eligible     0\n",
      "last_training_date     0\n",
      "department             0\n",
      "work_experience        0\n",
      "projects_completed     0\n",
      "hours_worked_weekly    0\n",
      "work_mode              0\n",
      "last_promotion_date    0\n",
      "satisfaction_score     0\n",
      "overtime_hours         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Load the dataset\n",
    "df = pd.read_csv('employee_insights.csv')\n",
    "\n",
    "#Initial examination\n",
    "print(\"First few rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nDataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "# Check initial missing values\n",
    "print(\"\\nMissing values before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Handle missing numeric values\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# Handle missing categorical values\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "df[categorical_cols] = df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# Verify missing values have been handled\n",
    "print(\"\\nRemaining missing values after cleaning:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9634587e",
   "metadata": {},
   "source": [
    "### Activity 2: Date Standardization - Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81db6f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dates sample:\n",
      "0    15/08/2023\n",
      "1    15/08/2023\n",
      "2    15/08/2023\n",
      "3    15/08/2023\n",
      "4    15/08/2023\n",
      "Name: last_training_date, dtype: object\n",
      "\n",
      "Promotion dates sample:\n",
      "0    2022-05-10\n",
      "1    05-10-2022\n",
      "2    10/05/2022\n",
      "3    05-10-2022\n",
      "4    2022-05-10\n",
      "Name: last_promotion_date, dtype: object\n",
      "\n",
      "Updated data types:\n",
      "Training date dtype: datetime64[ns]\n",
      "Promotion date dtype: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Examine date formats\n",
    "print(\"Training dates sample:\")\n",
    "print(df['last_training_date'].head())\n",
    "\n",
    "print(\"\\nPromotion dates sample:\")\n",
    "print(df['last_promotion_date'].head())\n",
    "\n",
    "# Convert dates to datetime\n",
    "df['last_training_date'] = pd.to_datetime(df['last_training_date'], format='mixed')\n",
    "df['last_promotion_date'] = pd.to_datetime(df['last_promotion_date'], format='mixed')\n",
    "\n",
    "# Verify conversion\n",
    "print(\"\\nUpdated data types:\")\n",
    "print(\"Training date dtype:\", df['last_training_date'].dtype)\n",
    "print(\"Promotion date dtype:\", df['last_promotion_date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4c396f",
   "metadata": {},
   "source": [
    "### Activity 3: Salary Data Cleaning - Solution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c1c937a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original salary values:\n",
      "0    $104328\n",
      "1     $64761\n",
      "2    $104328\n",
      "3    $104328\n",
      "4     $61486\n",
      "Name: salary, dtype: object\n",
      "\n",
      "Cleaned salary values:\n",
      "0    104328.0\n",
      "1     64761.0\n",
      "2    104328.0\n",
      "3    104328.0\n",
      "4     61486.0\n",
      "Name: salary, dtype: float64\n",
      "Salary dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Examine current salary format\n",
    "print(\"Original salary values:\")\n",
    "print(df['salary'].head())\n",
    "\n",
    "# Clean salary column\n",
    "df['salary'] = df['salary'].str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n",
    "# Verify conversion\n",
    "print(\"\\nCleaned salary values:\")\n",
    "print(df['salary'].head())\n",
    "print(\"Salary dtype:\", df['salary'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb193e6",
   "metadata": {},
   "source": [
    "### Activity 4: Categorical Data Normalization - Solution Code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1387270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original work_mode values:\n",
      "work_mode\n",
      "HYBRID         35\n",
      "remote work    19\n",
      "On-site        17\n",
      "Remote         15\n",
      "Hybrid         14\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Standardized work_mode values:\n",
      "work_mode\n",
      "hybrid       49\n",
      "remote       34\n",
      "in-office    17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Final Data Types:\n",
      "employee_id                    object\n",
      "age                           float64\n",
      "salary                        float64\n",
      "promotion_eligible             object\n",
      "last_training_date     datetime64[ns]\n",
      "department                     object\n",
      "work_experience                object\n",
      "projects_completed            float64\n",
      "hours_worked_weekly           float64\n",
      "work_mode                      object\n",
      "last_promotion_date    datetime64[ns]\n",
      "satisfaction_score            float64\n",
      "overtime_hours                float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Examine work_mode values\n",
    "print(\"Original work_mode values:\")\n",
    "print(df['work_mode'].value_counts())\n",
    "\n",
    "# Standardize work_mode values\n",
    "df['work_mode'] = df['work_mode'].str.strip().str.lower()\n",
    "\n",
    "# Group similar values\n",
    "df['work_mode'] = df['work_mode'].replace({\n",
    "    'remote': 'remote',\n",
    "    'remote work': 'remote',\n",
    "    'on-site': 'in-office',\n",
    "    'hybrid': 'hybrid'\n",
    "})\n",
    "\n",
    "# Verify standardization\n",
    "print(\"\\nStandardized work_mode values:\")\n",
    "print(df['work_mode'].value_counts())\n",
    "\n",
    "# Final Verification\n",
    "print(\"\\nFinal Data Types:\")\n",
    "print(df.dtypes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
